{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52f7d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = {\"headers\":{\"orders\":[\"order_number\",\"customer_number\"]},\"rows\":{\"orders\":[[1,1],[2,2],[3,3],[4,3]]}}\n",
    "pd.DataFrame(d['rows']['orders'], columns=d['headers']['orders']).to_csv(\"./orders.txt\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed37531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"586\").config(\"pyspark.sql.shuffle.partition\",\"4\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b952ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+\n",
      "|order_number|customer_number|\n",
      "+------------+---------------+\n",
      "|           1|              1|\n",
      "|           2|              2|\n",
      "|           3|              3|\n",
      "|           4|              3|\n",
      "+------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "o = spark.read.option(\"header\", True).csv(\"./orders.txt\")\n",
    "o.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96626c7c",
   "metadata": {},
   "source": [
    "Write an SQL query to find the customer_number for the customer who has placed the largest number of orders.\n",
    "\n",
    "The test cases are generated so that exactly one customer will have placed more orders than any other customer.\n",
    "\n",
    "The query result format is in the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f5159be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(customer_number='3')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "o.groupBy(\"customer_number\").count().withColumnRenamed(\"count\", \"numberOfOrders\").orderBy(\"numberOfOrders\", ascending=False).select(\"customer_number\").first()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
